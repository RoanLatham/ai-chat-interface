<p align="center">
  <img src="./icon/AII-icon.ico" alt="Local AI Chat Logo" width="72"/>
</p>

<h1 align="center">Local AI Chat</h1>

<p align="center">
  A privacy-focused conversational AI app powered by local LLMs, featuring branching conversations
</p>
<p align="center">
  Built with 1 HTML file and 1 Python script
</p>

<p align="center">
  <img alt="GitHub License" src="https://img.shields.io/badge/License-MIT-green">
  <img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/RoanLatham/ai-chat-interface">
  <img alt="GitHub issues" src="https://img.shields.io/github/issues/RoanLatham/ai-chat-interface">
</p>

<p align="center">
  <img alt="Flask" src="https://img.shields.io/badge/Flask-v3.0.0-blue">
  <img alt="llama-cpp-python" src="https://img.shields.io/badge/llama--cpp--python-v0.3.5-blue">
  <img alt="Python" src="https://img.shields.io/badge/Python-v3.11.7-blue">
</p>

<p align="center">
  <a href="#key-features">Key Features</a> â€¢
  <a href="#installation">Installation</a> â€¢
  <a href="#usage">Usage</a> â€¢
  <a href="#documentation">Documentation</a> â€¢
  <a href="#development">Development</a> â€¢
  <a href="#contributing">Contributing</a> â€¢
  <a href="#license">License</a>
</p>

<details open>
<summary><h2>âœ¨ Key Features</h2></summary>

- **ğŸ”’ Completely Local & Private** - All processing happens on your machine with no data shared externally
- **ğŸ§  Multiple AI Model Support** - Use different GGUF-format models suited to your hardware and requirements
- **ğŸŒ¿ Branching Conversations** - Explore different responses and maintain multiple conversation paths
- **âš™ï¸ Custom System Prompts** - Tailor your AI's behavior and capabilities
- **ğŸ“ Markdown Rendering** - Beautiful formatting of AI responses with syntax highlighting
- **ğŸ’» Code Syntax Highlighting** - Clear, readable code snippets in responses
- **ğŸŒ Web-Based Interface** - Intuitive browser UI with no installation requirements
- **ğŸ’¾ Conversation Management** - Save, load, and organize your conversation history
- **ğŸ”„ Versioning System** - Ensures backward compatibility of conversation files
- **ğŸ› ï¸ Developer Tools** - Advanced editing and management for conversation files

</details>

<details open>
<summary><h2>ğŸ“¦ Installation</h2></summary>

### Prerequisites

- Windows 10/11 (for packaged versions) or any Windows/Linux/macOS system (for source installation)
- Python minimum 3.6 or higher (if running from source)
- GGUF-format language models

### Windows Only: Packaged Versions

<details>
<summary><h4>ğŸ’¼ Portable Version</h4></summary>

1. Download the portable ZIP from the [Releases](https://github.com/RoanLatham/ai-chat-interface/releases) page
2. Extract to any location
3. Run `LocalAIChat.exe`

</details>

<details>
<summary><h4>ğŸ’¿ Windows Installer</h4></summary>

1. Download the latest installer from the [Releases](https://github.com/RoanLatham/ai-chat-interface/releases) page
2. Run the installer and follow the on-screen instructions
3. Launch the application from the Start Menu or Desktop shortcut

</details>

<details>
<summary><h3>ğŸ“¦ All Platforms: From Source</h3></summary>

This method works on Windows, macOS, and Linux.

```bash
# Clone the repository
git clone https://github.com/RoanLatham/ai-chat-interface.git

# Navigate to the project directory
cd ai-chat-interface

# Optional but recommended: Create a virtual environment
python -m venv venv

# Activate the virtual environment
# On Windows:
venv\Scripts\activate.ps1
# On macOS/Linux:
# source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the application
python local-ai-chat-app.py
```

</details>

<details>
<summary><h4>ğŸ¤– Setting Up AI Models</h4></summary>

After installation:

1. Place GGUF model files in the `ai_models` directory
2. Refresh or open the web interface
3. Select your model from the dropdown in the top center of the page

<details>
<summary>ğŸ” Where to find compatible models</summary>

Compatible GGUF models can be downloaded from:

- [Hugging Face](https://huggingface.co/models?sort=downloads&search=gguf)

Recommended starter models:

- Llama-3-8B-Instruct (various quantizations)
- Mistral-7B-Instruct (various quantizations)
- Phi-3-mini-4k-instruct (various quantizations)

Choose quantization level based on your hardware capabilities:

- Q4_K_M: Good balance of quality and performance
- Q5_K_M: Better quality, more memory usage
- Q8_0: High quality, requires more memory, storage, and compute

</details>

</details>

</details>

<details open>
<summary><h2>ğŸš€ Usage</h2></summary>

<details>
<summary><h4>ğŸš€ Starting the Application</h4></summary>

1. Launch the application using the desktop shortcut or executable
2. A browser window will automatically open to `http://localhost:5000`
3. If the browser doesn't open automatically, manually navigate to this address

</details>

<details>
<summary><h4>âœ¨ Features</h4></summary>

<details>
<summary>ğŸ’¬ Creating a New Conversation</summary>

1. Click on the "New Conversation" button in the sidebar
2. Start typing a message and press Enter or click Send
3. Wait for the AI to generate a response

</details>

<details>
<summary>ğŸŒ¿ Working with Branches</summary>

1. To edit a message and create a new branch, click the "Edit" button on any message
2. To regenerate an AI response, click the "Regenerate" button
3. Navigate between branches using the left/right arrows that appear at branching points

</details>

<details>
<summary>ğŸ”€ Using Different Models</summary>

1. Select a model from the dropdown menu in the upper-right corner
2. The model will be loaded when you send your next message

</details>

<details>
<summary>âš™ï¸ Customizing System Prompts</summary>

1. Click the "Edit System Prompt" button in the header
2. Modify the prompt as desired
3. Click "Save" to apply the changes

</details>

<details>
<summary><h4>ğŸ“‚ Managing Conversations</h4></summary>

- **âœï¸ Rename**: Click the menu icon next to a conversation and select "Rename"
- **ğŸ—‘ï¸ Delete**: Click the menu icon next to a conversation and select "Delete"
- **ğŸ”€ Switch Branches**: Navigate to a specific branch using the branch indicators in the chat

</details>

</details>

<details>
<summary><h4>âš ï¸ Troubleshooting</h4></summary>

- If models aren't appearing, ensure they're placed in the `ai_models` directory with a `.gguf` extension
- For slow responses, try a smaller or more optimized model
- Check the `logs` directory for detailed error information

</details>

</details>

<details open>
<summary><h2>ğŸ“ Documentation</h2></summary>

- [Local AI Chat App Documentation](./Docs/local_ai_chat_app_documentation.md) - Core application functionality
- [Conversation Module Documentation](./Docs/conversation_module_documentation.md) - Conversation data structure
- [Conversation Versioning Documentation](./Docs/conversation_versioning.md) - File compatibility system
- [Conversation Editor Documentation](./Docs/conversation_editor_documentation.md) - Developer tools

</details>

<details open>
<summary><h2>ğŸ’» Development</h2></summary>

<details>
<summary><h4>ğŸ“ Project Structure</h4></summary>

```
ai-chat-interface/
â”œâ”€â”€ ai_models/             # AI model files (.gguf)
â”œâ”€â”€ build_tools/           # Packaging and build scripts
â”œâ”€â”€ conversations/         # Saved conversation files
â”œâ”€â”€ example_conversations/ # Conversation files included in the build process
â”œâ”€â”€ docs/                  # Documentation files
â”œâ”€â”€ icon/                  # Application icons
â”œâ”€â”€ logs/                  # Application logs
â”œâ”€â”€ local-ai-chat-app.py   # Main application
â”œâ”€â”€ conversation.py        # Conversation data structure
â”œâ”€â”€ chat-interface.html    # Web interface
â”œâ”€â”€ system-prompt.txt      # Top-level AI system prompt
â””â”€â”€ requirements.txt       # Python dependencies
```

</details>

<details>
<summary><h4>ğŸ”¨ Building the Application</h4></summary>

```bash
# Navigate to the build_tools directory
cd build_tools

# Run the master build script
python build_master.bat

# Build without creating an installer
python build_master.bat --no-installer

# Skip dependency checks
python build_master.bat --skip-deps
```

</details>

<details>
<summary><h4>ğŸ”§ Conversation Editor Tool</h4></summary>

The project includes a developer tool for managing conversation files:

```bash
# Run the conversation editor
python conversation_editor.py

# Open a specific conversation file
python conversation_editor.py path/to/conversation.pickle

# Set version for a file without launching interactive mode
python conversation_editor.py path/to/conversation.pickle --set-version 1.1.0
```

See [Conversation Editor Documentation](./Docs/conversation_editor_documentation.md) for more details

</details>

</details>

<details open>
<summary><h2>ğŸ¤ Contributing</h2></summary>

Contributions to improve Local AI Chat are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add some amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

Before submitting, please ensure:

- Your code follows the project's coding style
- You've added/updated documentation as necessary

</details>

<details open>
<summary><h2>ğŸ“„ License</h2></summary>

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

</details>

<details open>
<summary><h2>ğŸ‘ Acknowledgements</h2></summary>

- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) - Python bindings for llama.cpp
- [Flask](https://flask.palletsprojects.com/) - Server framework
- [Marked.js](https://marked.js.org/) - Markdown parser
- [Highlight.js](https://highlightjs.org/) - Syntax highlighting

</details>

---

<div align="center">
Made with â¤ï¸ by Roan Latham

[Report Bug](https://github.com/RoanLatham/ai-chat-interface/issues) Â· [Request Feature](https://github.com/RoanLatham/ai-chat-interface/issues)

</div>
